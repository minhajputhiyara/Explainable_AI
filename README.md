# Explainable_AI
This repository provides simple implementations of popular Explainable AI (XAI) techniques, including LIME, SHAP, Counterfactual Explanations, Occlusion, Grad-CAM, Adversarial Attacks (FGSM), and Random Forest Interpretability. It offers easy-to-follow code to enhance the transparency and interpretability of machine learning models.
